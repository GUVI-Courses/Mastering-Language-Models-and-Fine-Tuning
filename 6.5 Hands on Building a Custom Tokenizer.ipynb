{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed5879eef20f4e8ebeb3b8cee143288a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a1f7279f88e46ecb3646bb7a26c1972",
              "IPY_MODEL_c16ca7bdf3c6471ebbcd099d1fbf2448",
              "IPY_MODEL_dc536cdcb04f421fb88a9515c744e0a1"
            ],
            "layout": "IPY_MODEL_c99266ad6fb245389b14e8e1b54b526b"
          }
        },
        "7a1f7279f88e46ecb3646bb7a26c1972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f58f3276aba4047b85f2c56e4b95cf7",
            "placeholder": "​",
            "style": "IPY_MODEL_431b5a6531844e30889c2f2c8d21cf78",
            "value": "model.safetensors: 100%"
          }
        },
        "c16ca7bdf3c6471ebbcd099d1fbf2448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35bf14d20c694383a81f6b25d3d408f4",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b3e9546a6bb4d99a6c88376984d62ce",
            "value": 440449768
          }
        },
        "dc536cdcb04f421fb88a9515c744e0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be6b148cafa2440696b4554bc5202431",
            "placeholder": "​",
            "style": "IPY_MODEL_9f7d7c521a804800ad47131d1e0af91c",
            "value": " 440M/440M [00:02&lt;00:00, 239MB/s]"
          }
        },
        "c99266ad6fb245389b14e8e1b54b526b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f58f3276aba4047b85f2c56e4b95cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "431b5a6531844e30889c2f2c8d21cf78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35bf14d20c694383a81f6b25d3d408f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b3e9546a6bb4d99a6c88376984d62ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be6b148cafa2440696b4554bc5202431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f7d7c521a804800ad47131d1e0af91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyotidabass/-Training-and-Customizing-Tokenizers/blob/main/Training_and_Customizing_Tokenizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Create dummy data\n",
        "data = {\n",
        "    \"text\": [\n",
        "        \"This is a sample sentence.\",\n",
        "        \"This is another sample sentence.\",\n",
        "        \"I love playing football.\",\n",
        "        \"I love playing basketball.\",\n",
        "        \"This is a new sentence with [NEW_TOKEN].\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Convert dummy data to pandas dataframe\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create a tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Print the original tokens\n",
        "print(\"Original Tokens:\")\n",
        "print(tokenizer.encode(df[\"text\"][0]))\n",
        "\n",
        "# Customize the tokenizer by adding new tokens\n",
        "tokenizer.add_tokens([\"[NEW_TOKEN]\"])\n",
        "\n",
        "# Print the customized tokens\n",
        "print(\"\\nCustomized Tokens:\")\n",
        "print(tokenizer.encode(df[\"text\"][4]))\n",
        "\n",
        "# Train the tokenizer on the dummy data using train_new_from_iterator\n",
        "# This method is used to train the tokenizer on new data.\n",
        "tokenizer.train_new_from_iterator(df[\"text\"], vocab_size=len(tokenizer)) #vocab_size can be adjusted\n",
        "#Print the trained tokens\n",
        "print(\"\\nTrained Tokens:\")\n",
        "print(tokenizer.encode(df[\"text\"][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZJDHOeLst7h",
        "outputId": "60fded66-263c-413d-e9dc-5e7a5467f11c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14761a3290954d13bed86e7af538ca29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c14a4f1252c74aeea9d040a93ac844d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f8e3cc8382e4abaa2d976bd2a2f5bf4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37a0e870010e497bb81a1c106c0d9268"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens:\n",
            "[101, 2023, 2003, 1037, 7099, 6251, 1012, 102]\n",
            "\n",
            "Customized Tokens:\n",
            "[101, 2023, 2003, 1037, 2047, 6251, 2007, 30522, 1012, 102]\n",
            "\n",
            "Trained Tokens:\n",
            "[101, 2023, 2003, 1037, 7099, 6251, 1012, 102]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here's a simple real-life application using Python code for Training  Tokenizers:"
      ],
      "metadata": {
        "id": "pa1bkjX3s1e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load the dummy dataset\n",
        "df = pd.DataFrame({\n",
        "    \"review\": [\n",
        "        \"I loved the movie!\",\n",
        "        \"It was a terrible film.\",\n",
        "        \"The acting was great.\",\n",
        "        \"The special effects were amazing.\",\n",
        "        \"I didn't like it.\"\n",
        "    ],\n",
        "    \"sentiment\": [1, 0, 1, 1, 0]\n",
        "})\n",
        "\n",
        "# Create a tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Preprocess the text data\n",
        "preprocessed_reviews = []\n",
        "for review in df[\"review\"]:\n",
        "    preprocessed_review = tokenizer.encode(review, add_special_tokens=True)\n",
        "    preprocessed_reviews.append(preprocessed_review)\n",
        "\n",
        "# Create a custom dataset class\n",
        "class MovieReviewDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, preprocessed_reviews, labels):\n",
        "        self.preprocessed_reviews = preprocessed_reviews\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\"input_ids\": self.preprocessed_reviews[idx], \"labels\": self.labels[idx]}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.preprocessed_reviews)\n",
        "\n",
        "# Create a dataset instance\n",
        "dataset = MovieReviewDataset(preprocessed_reviews, df[\"sentiment\"])\n",
        "\n",
        "# Create a DataLoader for batching\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=lambda batch: tokenizer.pad(batch, padding='longest', return_tensors='pt'))\n",
        "# Added collate_fn to pad sequences to the longest length in the batch\n",
        "\n",
        "# Train a model for sentiment analysis\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        # Move input_ids and labels to device within the loop\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Pass attention_mask to the model\n",
        "        outputs = model(input_ids, labels=labels, attention_mask=batch['attention_mask'].to(device)) # Pass attention_mask to model\n",
        "        loss = outputs.loss  # Access loss using outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}\")  # Divide by the number of batches\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "test_review = \"I loved the movie!\"\n",
        "test_review = tokenizer.encode(test_review, add_special_tokens=True)\n",
        "test_review = torch.tensor(test_review).unsqueeze(0).to(device)  # Add batch dimension\n",
        "output = model(test_review)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ed5879eef20f4e8ebeb3b8cee143288a",
            "7a1f7279f88e46ecb3646bb7a26c1972",
            "c16ca7bdf3c6471ebbcd099d1fbf2448",
            "dc536cdcb04f421fb88a9515c744e0a1",
            "c99266ad6fb245389b14e8e1b54b526b",
            "9f58f3276aba4047b85f2c56e4b95cf7",
            "431b5a6531844e30889c2f2c8d21cf78",
            "35bf14d20c694383a81f6b25d3d408f4",
            "4b3e9546a6bb4d99a6c88376984d62ce",
            "be6b148cafa2440696b4554bc5202431",
            "9f7d7c521a804800ad47131d1e0af91c"
          ]
        },
        "id": "xDXg4EKBrhLJ",
        "outputId": "b5e75865-d038-444d-f9aa-f838cba66153"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed5879eef20f4e8ebeb3b8cee143288a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.9257032672564188\n",
            "Epoch 2, Loss: 0.665668268998464\n",
            "Epoch 3, Loss: 0.6597481966018677\n",
            "Epoch 4, Loss: 0.4813595612843831\n",
            "Epoch 5, Loss: 0.4333665768305461\n",
            "SequenceClassifierOutput(loss=None, logits=tensor([[-0.5860,  0.4704]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here's a Python code with simplest explanation for Customizing Tokenizers:\n",
        "Customizing Tokenizers\n",
        "Goal: Customize a tokenizer to recognize specific words or phrases."
      ],
      "metadata": {
        "id": "pknKKnNhtaL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the dummy dataset\n",
        "df = pd.DataFrame({\n",
        "    \"text\": [\n",
        "        \"I loved the movie!\",\n",
        "        \"It was a terrible film.\",\n",
        "        \"The acting was great.\",\n",
        "        \"The special effects were amazing.\",\n",
        "        \"I didn't like it.\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Create a tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Customize the tokenizer\n",
        "tokenizer.add_tokens([\"[MOVIE]\", \"[ACTING]\"])\n",
        "\n",
        "# Preprocess the text data\n",
        "preprocessed_text = []\n",
        "for text in df[\"text\"]:\n",
        "    preprocessed_text.append(tokenizer.encode(text, add_special_tokens=True))\n",
        "\n",
        "# Print the preprocessed text\n",
        "print(preprocessed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYI901GHtQUF",
        "outputId": "7c836166-a763-4b94-df8e-b5cd45a6fa78"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[101, 1045, 3866, 1996, 3185, 999, 102], [101, 2009, 2001, 1037, 6659, 2143, 1012, 102], [101, 1996, 3772, 2001, 2307, 1012, 102], [101, 1996, 2569, 3896, 2020, 6429, 1012, 102], [101, 1045, 2134, 1005, 1056, 2066, 2009, 1012, 102]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customizing Tokenizers with Special Tokens\n",
        "\n",
        "Goal: Customize a tokenizer to recognize special tokens."
      ],
      "metadata": {
        "id": "VrjT02SqtnVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the dummy dataset\n",
        "df = pd.DataFrame({\n",
        "    \"text\": [\n",
        "        \"I loved the movie!\",\n",
        "        \"It was a terrible film.\",\n",
        "        \"The acting was great.\",\n",
        "        \"The special effects were amazing.\",\n",
        "        \"I didn't like it.\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Create a tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "\n",
        "# Customize the tokenizer with special tokens\n",
        "tokenizer.add_special_tokens({'additional_special_tokens': [\"[CLS]\", \"[SEP]\"]})\n",
        "\n",
        "# Preprocess the text data\n",
        "preprocessed_text = []\n",
        "for text in df[\"text\"]:\n",
        "    preprocessed_text.append(tokenizer.encode(text, add_special_tokens=True))\n",
        "\n",
        "# Print the preprocessed text\n",
        "print(preprocessed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruuH6rQctoyc",
        "outputId": "8fe0ba0a-3484-4785-963c-ab9c9a9812e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[101, 1045, 3866, 1996, 3185, 999, 102], [101, 2009, 2001, 1037, 6659, 2143, 1012, 102], [101, 1996, 3772, 2001, 2307, 1012, 102], [101, 1996, 2569, 3896, 2020, 6429, 1012, 102], [101, 1045, 2134, 1005, 1056, 2066, 2009, 1012, 102]]\n"
          ]
        }
      ]
    }
  ]
}